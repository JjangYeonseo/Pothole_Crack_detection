import os
import yaml
import torch
import numpy as np
from ultralytics import YOLO
from pathlib import Path
import cv2
import time
from datetime import datetime

class FastOptimizedYOLOv8Trainer:
    def __init__(self, data_dir, model_name="yolov8s-seg.pt"):
        self.data_dir = Path(data_dir)
        self.model_name = model_name
        self.class_names = ['ac', 'lctc', 'pc', 'ph']
        
        # ì†ë„-ì„±ëŠ¥ ê· í˜•ì„ ìœ„í•œ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜
        # ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ìœ¼ë¡œ ë¯¸ë¦¬ ìµœì í™”ëœ ê°’
        self.class_weights = [1.0, 2.2, 1.0, 2.0]  # ac, lctc, pc, ph
        
        # GPU ìµœì í™”
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”
            torch.backends.cudnn.benchmark = True
            gpu_name = torch.cuda.get_device_name(0)
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
            print(f"ğŸš€ GPU: {gpu_name} ({gpu_memory:.1f}GB) - ê³ ì† ëª¨ë“œ")
        else:
            print("âš ï¸ CPU ëª¨ë“œ - ì†ë„ ì œí•œì ")

    def create_data_yaml(self, output_path="dataset.yaml"):
        data_config = {
            'path': str(self.data_dir.absolute()),
            'train': 'train/images',
            'val': 'val/images',
            'nc': len(self.class_names),
            'names': self.class_names
        }
        with open(output_path, 'w') as f:
            yaml.dump(data_config, f, default_flow_style=False)
        return output_path

    def get_fast_optimized_settings(self):
        """ì†ë„-ì„±ëŠ¥ ê· í˜• ìµœì í™” ì„¤ì • (2-3ì‹œê°„ ëª©í‘œ)"""
        return {
            # ğŸš€ ì†ë„ ìµœì í™”ëœ ê¸°ë³¸ ì„¤ì •
            'epochs': 200,          # 250 â†’ 200 (20% ì‹œê°„ ë‹¨ì¶•)
            'imgsz': 640,
            'batch': 16,            # ë°°ì¹˜ í¬ê¸° ìœ ì§€ (ì„±ëŠ¥ ìœ„í•´)
            'workers': 4,           # 2 â†’ 4 (ë°ì´í„° ë¡œë”© ê°€ì†)
            'patience': 25,         # ì¡°ê¸° ì¢…ë£Œë¡œ ì‹œê°„ ì ˆì•½
            
            # ğŸ”¥ ë©”ëª¨ë¦¬ ìµœì í™” + ì†ë„
            'cache': 'ram',         # False â†’ 'ram' (ì²« ì—í­ í›„ ê°€ì†)
            'amp': True,            # Mixed precision (ì†ë„ í–¥ìƒ)
            'multi_scale': False,   # True â†’ False (ì†ë„ í–¥ìƒ)
            'overlap_mask': True,
            'mask_ratio': 4,
            'close_mosaic': 15,
            
            # âš¡ ë¹ ë¥¸ ìˆ˜ë ´ì„ ìœ„í•œ ì˜µí‹°ë§ˆì´ì €
            'optimizer': 'AdamW',
            'lr0': 0.002,           # ì•½ê°„ ë†’ì€ í•™ìŠµë¥  (ë¹ ë¥¸ ìˆ˜ë ´)
            'lrf': 0.0001,
            'momentum': 0.937,
            'weight_decay': 0.0006,
            'warmup_epochs': 3.0,
            'warmup_momentum': 0.8,
            'warmup_bias_lr': 0.1,
            
            # ğŸ¯ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìµœì í™” (ê²€ì¦ëœ ê°’)
            'box': 7.0,
            'cls': 0.7,             # ë¶„ë¥˜ ì„±ëŠ¥ ê°•í™”
            'dfl': 1.3,
            
            # ğŸ¨ íš¨ê³¼ì ì¸ ë°ì´í„° ì¦ê°• (ê³¼ë„í•˜ì§€ ì•Šê²Œ)
            'hsv_h': 0.01,          # ìƒ‰ìƒ ë³€í™” ìµœì†Œí™” (ì†ë„)
            'hsv_s': 0.3,
            'hsv_v': 0.15,
            'degrees': 3.0,         # ì ë‹¹í•œ íšŒì „
            'translate': 0.08,      # ì ë‹¹í•œ ì´ë™
            'scale': 0.25,          # ì ë‹¹í•œ í¬ê¸° ë³€í™”
            'shear': 1.0,           # ì „ë‹¨ ë³€í™˜ ìµœì†Œí™”
            'perspective': 0.0001,  # ì›ê·¼ ë³€í™˜ ìµœì†Œí™”
            'flipud': 0.0,
            'fliplr': 0.5,
            'mosaic': 0.9,          # 1.0 â†’ 0.9 (ì†ë„ í–¥ìƒ)
            'mixup': 0.05,          # 0.1 â†’ 0.05 (ì†ë„ í–¥ìƒ)
            'copy_paste': 0.0,
            
            # ğŸ“ˆ í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬
            'cos_lr': True,
            
            # ğŸ’¾ ì €ì¥ ìµœì í™”
            'save': True,
            'save_period': 30,      # 25 â†’ 30 (I/O ê°ì†Œ)
            'val': True,
            'plots': True,
            'verbose': True,
            
            # ğŸ§  ì„±ëŠ¥ í–¥ìƒ ì„¤ì • (ì†ë„ ì˜í–¥ ìµœì†Œ)
            'dropout': 0.08,        # 0.1 â†’ 0.08 (ê°€ë²¼ìš´ ì •ê·œí™”)
            'label_smoothing': 0.03, # 0.05 â†’ 0.03 (ê°€ë²¼ìš´ ìŠ¤ë¬´ë”©)
        }

    def quick_dataset_analysis(self):
        """ë¹ ë¥¸ ë°ì´í„°ì…‹ ë¶„ì„"""
        train_dir = self.data_dir / 'train' / 'images'
        val_dir = self.data_dir / 'val' / 'images'
        
        train_count = len(list(train_dir.glob("*.jpg"))) + len(list(train_dir.glob("*.png")))
        val_count = len(list(val_dir.glob("*.jpg"))) + len(list(val_dir.glob("*.png")))
        
        print(f"ğŸ“Š ë°ì´í„°ì…‹: í•™ìŠµ {train_count}ì¥, ê²€ì¦ {val_count}ì¥")
        print(f"ğŸ¯ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜: {dict(zip(self.class_names, self.class_weights))}")
        
        return train_count, val_count

    def fast_train(self):
        """ë¹ ë¥¸ ê³ ì„±ëŠ¥ í•™ìŠµ"""
        print(f"âš¡ ë¹ ë¥¸ YOLOv8 ì„¸ê·¸ë©˜í…Œì´ì…˜ í•™ìŠµ ì‹œì‘")
        print(f"ğŸ¯ ëª©í‘œ: 2-3ì‹œê°„ ë‚´ 85%+ ì„±ëŠ¥ ë‹¬ì„±")
        print("=" * 60)
        
        train_count, val_count = self.quick_dataset_analysis()
        
        # ì˜ˆìƒ í•™ìŠµ ì‹œê°„ ê³„ì‚°
        estimated_time = self.estimate_training_time(train_count)
        print(f"â±ï¸ ì˜ˆìƒ í•™ìŠµ ì‹œê°„: {estimated_time:.1f}ì‹œê°„")
        
        model = YOLO(self.model_name)
        data_yaml = self.create_data_yaml()
        
        args = self.get_fast_optimized_settings()
        args.update({
            'data': data_yaml,
            'device': 'cuda' if torch.cuda.is_available() else 'cpu',
            'project': 'runs/fast_segment',
            'name': f'fast_train_{self.data_dir.name}_{datetime.now().strftime("%m%d_%H%M")}',
            'exist_ok': True,
            'pretrained': True,
            'resume': False,
        })
        
        print(f"\nğŸš€ ê³ ì† í•™ìŠµ ì‹œì‘ - {datetime.now().strftime('%H:%M:%S')}")
        print(f"   âš™ï¸ ì—í­: {args['epochs']}")
        print(f"   ğŸ“¦ ë°°ì¹˜: {args['batch']}")
        print(f"   ğŸ§  ìºì‹œ: {args['cache']}")
        print(f"   âš¡ AMP: {args['amp']}")
        
        start_time = time.time()
        results = model.train(**args)
        training_time = time.time() - start_time
        
        print(f"\nâœ… í•™ìŠµ ì™„ë£Œ!")
        print(f"â±ï¸ ì‹¤ì œ ì†Œìš” ì‹œê°„: {training_time/3600:.1f}ì‹œê°„")
        print(f"ğŸ“ˆ ì‹œê°„ë‹¹ ì—í­: {args['epochs']/(training_time/3600):.1f}")
        
        return model, results

    def estimate_training_time(self, image_count):
        """í•™ìŠµ ì‹œê°„ ì¶”ì •"""
        # GPU ì„±ëŠ¥ì— ë”°ë¥¸ ëŒ€ëµì  ì¶”ì •
        if torch.cuda.is_available():
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
            if gpu_memory >= 10:  # RTX 3080, 4070 ì´ìƒ
                time_per_epoch = (image_count / 1000) * 0.8  # ë¶„
            elif gpu_memory >= 8:   # RTX 3070, 4060 ì´ìƒ  
                time_per_epoch = (image_count / 1000) * 1.2
            else:  # GTX 1660, RTX 3060 ì´í•˜
                time_per_epoch = (image_count / 1000) * 1.8
        else:
            time_per_epoch = (image_count / 1000) * 5.0  # CPUëŠ” ë§¤ìš° ëŠë¦¼
        
        total_minutes = time_per_epoch * 200  # 200 ì—í­
        return total_minutes / 60  # ì‹œê°„ ë‹¨ìœ„ë¡œ ë³€í™˜

    def fast_validate_with_target_check(self, model_path=None):
        """ë¹ ë¥¸ ê²€ì¦ + ëª©í‘œ ë‹¬ì„± í™•ì¸"""
        if model_path:
            model = YOLO(model_path)
        else:
            runs_dir = Path('runs/fast_segment')
            if runs_dir.exists():
                latest_run = max([d for d in runs_dir.iterdir() if d.is_dir()], 
                               key=os.path.getctime)
                model = YOLO(latest_run / 'weights' / 'best.pt')
                print(f"ğŸ” ëª¨ë¸: {latest_run / 'weights' / 'best.pt'}")
            else:
                print("âŒ í•™ìŠµëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
                return None

        data_yaml = self.create_data_yaml()
        
        print("\nğŸ”¬ ì„±ëŠ¥ ê²€ì¦ ì¤‘...")
        results = model.val(
            data=data_yaml,
            imgsz=640,
            batch=16,  # ê²€ì¦ë„ ë¹ ë¥´ê²Œ
            conf=0.25,
            iou=0.6,
            device='cuda' if torch.cuda.is_available() else 'cpu',
            verbose=True
        )
        
        try:
            if hasattr(results, 'seg') and results.seg is not None:
                maps_50 = results.seg.map50
            else:
                maps_50 = results.box.map50

            print(f"\nğŸ¯ ë¹ ë¥¸ í•™ìŠµ ìµœì¢… ê²°ê³¼:")
            print("=" * 40)
            
            success_count = 0
            total_gap = 0
            
            for i, name in enumerate(self.class_names):
                if isinstance(maps_50, (list, np.ndarray)) and len(maps_50) > i:
                    m50 = maps_50[i]
                else:
                    m50 = maps_50
                
                status = "âœ…" if m50 >= 0.85 else "âŒ"
                if m50 >= 0.85:
                    success_count += 1
                else:
                    total_gap += (0.85 - m50)
                    
                print(f"  {name:>4}: {m50:.3f} {status}")

            avg_map = np.mean(maps_50) if isinstance(maps_50, (list, np.ndarray)) else maps_50
            
            print(f"  í‰ê· : {avg_map:.3f}")
            print(f"  ë‹¬ì„±: {success_count}/{len(self.class_names)} í´ë˜ìŠ¤")
            
            # ê²°ê³¼ í‰ê°€
            if success_count == len(self.class_names):
                print(f"\nğŸ‰ ì™„ë²½! ëª¨ë“  í´ë˜ìŠ¤ 85% ë‹¬ì„±!")
                print(f"âš¡ ë¹ ë¥¸ í•™ìŠµìœ¼ë¡œë„ ëª©í‘œ ë‹¬ì„± ì„±ê³µ!")
            elif success_count >= len(self.class_names) * 0.75:
                print(f"\nğŸ‘ ì–‘í˜¸! ëŒ€ë¶€ë¶„ í´ë˜ìŠ¤ ëª©í‘œ ê·¼ì ‘")
                print(f"ğŸ’¡ ì¶”ê°€ 50-100 ì—í­ì´ë©´ ì™„ì „ ë‹¬ì„± ê°€ëŠ¥")
            else:
                print(f"\nğŸ¤” ì¶”ê°€ ìµœì í™” í•„ìš”")
                print(f"ğŸ’¡ ì ì‘í˜• í•™ìŠµ ë˜ëŠ” ë°ì´í„° ë³´ê°• ê³ ë ¤")
                
        except Exception as e:
            print(f"âš ï¸ ì„±ëŠ¥ ë¶„ì„ ì‹¤íŒ¨: {e}")

        return results

    def quick_visualization(self, num_samples=10):
        """ë¹ ë¥¸ ê²°ê³¼ ì‹œê°í™”"""
        runs_dir = Path('runs/fast_segment')
        if runs_dir.exists():
            latest_run = max([d for d in runs_dir.iterdir() if d.is_dir()], 
                           key=os.path.getctime)
            model = YOLO(latest_run / 'weights' / 'best.pt')
        else:
            print("âŒ ì‹œê°í™”í•  ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            return

        image_dir = self.data_dir / 'val' / 'images'
        save_dir = Path("fast_inference_samples")
        save_dir.mkdir(parents=True, exist_ok=True)

        images = list(image_dir.glob("*.jpg")) + list(image_dir.glob("*.png"))
        selected_images = images[:num_samples]

        print(f"ğŸ–¼ï¸ {len(selected_images)}ì¥ ë¹ ë¥¸ ì‹œê°í™”...")
        
        for i, img_path in enumerate(selected_images):
            results = model(img_path, save=False, conf=0.25, iou=0.6)
            result_img = results[0].plot()
            save_path = save_dir / f"fast_result_{i:02d}_{img_path.stem}.jpg"
            cv2.imwrite(str(save_path), result_img)

        print(f"âœ… ë¹ ë¥¸ ì‹œê°í™” ì™„ë£Œ: {save_dir}")

    def run_fast_pipeline(self):
        """ë¹ ë¥¸ ì „ì²´ íŒŒì´í”„ë¼ì¸"""
        print("âš¡ ë¹ ë¥¸ YOLOv8 ì„¸ê·¸ë©˜í…Œì´ì…˜ íŒŒì´í”„ë¼ì¸")
        print("ğŸ¯ ëª©í‘œ: 2-3ì‹œê°„ ë‚´ ê³ ì„±ëŠ¥ ë‹¬ì„±")
        print("=" * 50)
        
        # 1. ë¹ ë¥¸ í•™ìŠµ
        model, train_results = self.fast_train()
        
        # 2. ë¹ ë¥¸ ê²€ì¦
        val_results = self.fast_validate_with_target_check()
        
        # 3. ë¹ ë¥¸ ì‹œê°í™”
        self.quick_visualization()
        
        print(f"\nâš¡ ë¹ ë¥¸ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
        return model, train_results, val_results

if __name__ == "__main__":
    import multiprocessing
    multiprocessing.set_start_method('spawn', force=True)
    
    data_dir = "C:/Users/dadab/Desktop/augmented_dataset"
    trainer = FastOptimizedYOLOv8Trainer(data_dir, model_name="yolov8s-seg.pt")
    
    # ë¹ ë¥¸ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    trainer.run_fast_pipeline()
